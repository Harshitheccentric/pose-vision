# Pose-Vision: Pose-Aware PPE Compliance (YOLOv8)

Real-time PPE compliance monitoring that fuses **object detection (PPE)** with **human pose estimation** to flag unsafe conditions on the fly.
Works on webcam or video files, overlays a clean HUD, and can log per-frame events for later analysis.

> **TL;DR** â†’ Plug camera/video in â†’ YOLOv8 (PPE + Pose) â†’ rule engine â†’ annotated video & JSON/CSV events.

---
## Demo(screen recording)

https://github.com/user-attachments/assets/cfacd6e7-adf3-48ca-b863-fad9ba254547

---

## âœ¨ Features

* ğŸ” **Dual-model fusion**: YOLOv8 PPE detection + YOLOv8 Pose keypoints
* â± **Per-frame compliance checks**: Hardhat, Mask, Safety Vest + posture cues
* ğŸ¥ **HUD overlays**: Bounding boxes, skeletons, compliance banners
* ğŸ“¹ **Webcam & file support**: Stream live or process pre-recorded videos
* ğŸ–¥ **Pure PyTorch**: No OpenVINO required
* ğŸ—‚ **Sample assets**: Ready-to-test images & videos

---

## ğŸ—‚ï¸ Repository Structure

```
pose-vision/
â”œâ”€ scripts/
â”‚  â”œâ”€ video_pipeline.py
â”‚  â”œâ”€ webcam_pipeline.py
â”‚  â””â”€ test/
â”‚     â”œâ”€ fine_tuned_posture.py
â”‚     â”œâ”€ improved_pose.py
â”‚     â”œâ”€ yolo_pose_image.py
â”‚     â”œâ”€ yolo_pose_video.py
â”‚     â”œâ”€ yolo_pose_webcam.py
â”‚     â””â”€ yolo_webcam.py
â”œâ”€ models/
â”‚  â”œâ”€ ppe.yaml
â”‚  â”œâ”€ yolov8n-pose.pt
â”‚  â””â”€ yolov8n-ppe.pt
â”œâ”€ assets/
â”‚  â”œâ”€ images/input.jpg
â”‚  â””â”€ videos/
â”‚     â”œâ”€ example1.mp4
â”‚     â”œâ”€ example2.mp4
â”‚     â”œâ”€ example_workers.mp4
â”‚     â”œâ”€ output_pose.mp4
â”‚     â””â”€ SCreenRec.mp4
â””â”€ Presentation/
   â”œâ”€ AI-Powered-PPE-Compliance-Monitoring.pptx.pdf
   â””â”€ Pose-Aware-PPE-Compliance-System.pptx.pdf
```

---

## ğŸ§  Models & Classes

* **Pose model**: `models/yolov8n-pose.pt`
* **PPE detector**: `models/yolov8n-ppe.pt`
* **Class map (`ppe.yaml`)**:

```
0: Hardhat
1: Mask
2: NO-Hardhat
3: NO-Mask
4: NO-Safety Vest
5: Person
6: Safety Cone
7: Safety Vest
8: machinery
9: vehicle
```

---

## âš™ï¸ Setup

> Python 3.9+ recommended.

```bash
# Clone repo
git clone https://github.com/Harshitheccentric/pose-vision.git
cd pose-vision

# Create virtual environment
python -m venv .venv
# Windows: .venv\Scripts\activate
# Linux/Mac:
source .venv/bin/activate

# Install dependencies
pip install --upgrade pip
pip install ultralytics opencv-python numpy torch torchvision pyyaml tqdm
```

âœ… No OpenVINO dependency needed.

---

## ğŸš€ Quickstart

### Run on webcam

```bash
python scripts/webcam_pipeline.py \
  --ppe-weights models/yolov8n-ppe.pt \
  --pose-weights models/yolov8n-pose.pt \
  --source 0 \
  --view \
  --save
```

### Run on a video file

```bash
python scripts/video_pipeline.py \
  --ppe-weights models/yolov8n-ppe.pt \
  --pose-weights models/yolov8n-pose.pt \
  --input assets/videos/example_workers.mp4 \
  --out runs/annotated_example.mp4 \
  --save-logs runs/example_events.json
```

---

## ğŸ§© How It Works

1. **PPE detection** â€“ YOLOv8 finds workers + gear
2. **Pose estimation** â€“ YOLOv8-Pose gives 17 keypoints
3. **Fusion** â€“ Match PPE boxes with persons (IoU overlap)
4. **Posture analysis** â€“ Angles & heuristics (from `fine_tuned_posture.py`)
5. **Rule engine** â€“ Flag violations (e.g., no helmet, bent spine)
6. **Output** â€“ Annotated video + optional JSON/CSV logs

---

## ğŸ—ï¸ Architecture

```mermaid
flowchart LR
  A[Video or Webcam Source] --> B[Frame Grab]
  B --> C1[YOLOv8 PPE Detection]
  B --> C2[YOLOv8 Pose Estimation]
  C1 --> D[Fusion and Association person to PPE overlap]
  C2 --> D
  D --> E[Posture Module angles and heuristics]
  E --> F[Compliance Rule Engine]
  F --> G[HUD Overlay boxes skeletons banners]
  F --> H[Event Logger JSON or CSV]
  G --> I[Annotated Video Output]
  H --> I
```

---

## ğŸ§ª Test Scripts

Located under `scripts/test/`:

* `yolo_webcam.py` â†’ PPE-only webcam
* `yolo_pose_webcam.py` â†’ Pose-only webcam
* `yolo_pose_video.py` â†’ Pose on video
* `yolo_pose_image.py` â†’ Pose on single image
* `improved_pose.py` â†’ Enhanced visualization
* `fine_tuned_posture.py` â†’ Posture classification logic

---

## ğŸ“Š Output Examples

**Video**: Annotated MP4 with skeletons & labels
**Logs** (JSON/CSV):

```json
{
  "frame": 123,
  "person_id": 5,
  "violations": ["NO-Hardhat", "NO-Safety Vest"],
  "posture": {"back_bend_deg": 32.1, "risk": "medium"},
  "timestamp": "00:00:04.10"
}
```

---

## ğŸ” Training (Optional)

### Train PPE detection

```bash
yolo detect train data=models/ppe.yaml model=yolov8n.pt imgsz=640 epochs=50 batch=16
```

### Train custom pose model

```bash
yolo pose train data=your_pose.yaml model=yolov8n-pose.pt imgsz=640 epochs=100
```

---

## ğŸ› Troubleshooting

* **No webcam feed** â†’ Ensure `--source 0` is correct and camera is free
* **CUDA not detected** â†’ Install correct PyTorch build for your GPU
* **Slow FPS** â†’ Use `yolov8n` for speed; scale up to `s/m/l` only if GPU allows

---
